{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "124e5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, sys\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35161b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accession = \"P02788\"\n",
    "variant_index = 'NCBI Reference SNP (rs) Report ALPHA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a25f9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_variation(accession: str) -> tuple[dict, pd.DataFrame]:\n",
    "    requestURL = f\"https://www.ebi.ac.uk/proteins/api/variation?offset=0&size=-1&accession={accession}\"\n",
    "    r = requests.get(requestURL, headers={ \"Accept\" : \"application/json\"})\n",
    "\n",
    "    if not r.ok:\n",
    "      r.raise_for_status()\n",
    "      sys.exit()\n",
    "\n",
    "    responseBody = r.text\n",
    "\n",
    "    data = json.loads(responseBody)[0]\n",
    "\n",
    "    features = pd.DataFrame(data.pop('features'))\n",
    "    return data, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75bb9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_aa_sequence(peptide_sequence: str, feature: dict) -> str:\n",
    "    \"\"\"\n",
    "    Get the reference amino acid for a given feature.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): The full protein sequence.\n",
    "        feature (dict): A feature dictionary containing 'begin' and 'end'.\n",
    "        \n",
    "    Returns:\n",
    "        str: The reference amino acid or None if not applicable.\n",
    "    \"\"\"\n",
    "    start = int(feature.get('begin'))\n",
    "    end = int(feature.get('end'))\n",
    "    \n",
    "    return peptide_sequence[start-1:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d804eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(feature: dict) -> str:\n",
    "    \"\"\"\n",
    "    Get the position of a feature in the protein sequence.\n",
    "\n",
    "    Args:\n",
    "        feature (dict): A feature dictionary containing 'begin' and 'end'.\n",
    "\n",
    "    Returns:\n",
    "        str: The position in the format \"start-end\".\n",
    "    \"\"\"\n",
    "    begin = feature.get('begin')\n",
    "    end = feature.get('end')\n",
    "    if begin == end:\n",
    "        return str(begin)\n",
    "    return f\"{feature.get('begin')}-{feature.get('end')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcfffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variant_id(feature: dict) -> str:\n",
    "    \"\"\"\n",
    "    Get the variant ID from a feature.\n",
    "\n",
    "    Args:\n",
    "        feature (dict): A feature dictionary.\n",
    "\n",
    "    Returns:\n",
    "        str: The variant ID or None if not applicable.\n",
    "    \"\"\"\n",
    "    xrefs = feature.get('xrefs', [])\n",
    "    for xref in xrefs:\n",
    "        if xref.get('id').startswith('rs'):\n",
    "            return xref.get('id')\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d97e70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(variant:str) -> str:\n",
    "    if not variant:\n",
    "        return ''\n",
    "        \n",
    "    try:\n",
    "        freq_url = f\"https://www.ncbi.nlm.nih.gov/snp/{variant}/download/frequency\"\n",
    "        r = requests.get(freq_url, headers={ \"Accept\" : \"application/json\"})\n",
    "        if not r.ok:\n",
    "            r.raise_for_status()\n",
    "        return r.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching frequency data for variant {variant}: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_frequency_reponse(responseBody: str) -> tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parse the frequency response body.\n",
    "\n",
    "    Args:\n",
    "        responseBody (str): The response body as a string.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed JSON data.\n",
    "    \"\"\"\n",
    "    if responseBody == '':\n",
    "        return {}, pd.DataFrame()\n",
    "\n",
    "    lines = responseBody.splitlines()\n",
    "    n_lines = len(lines)\n",
    "    i = 0\n",
    "\n",
    "    metadata = {}\n",
    "    header = []\n",
    "    rows = []\n",
    "\n",
    "    while i < n_lines:\n",
    "        line = lines[i]\n",
    "        tokens = line.split('\\t')\n",
    "\n",
    "        if len(tokens) == 2:\n",
    "            key = tokens[0].strip('# ')\n",
    "            value = tokens[1].strip()\n",
    "            metadata[key] = value\n",
    "        elif len(tokens) > 2:\n",
    "            if tokens[0].startswith('#'):\n",
    "                header = [t.strip('# ') for t in tokens]\n",
    "            else:\n",
    "                row = list(map(lambda x: 'NA' if x == \"\" else x, tokens))\n",
    "                rows.append(row)\n",
    "        elif len(tokens) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Unexpected line format at line {i}: {line}\")\n",
    "            sys.exit(1)\n",
    "        i += 1\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    df[variant_index] = metadata.get(variant_index)\n",
    "    return metadata, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cae633b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_alternative_sequences(df):\n",
    "    if 'alternativeSequence' not in df.columns:\n",
    "        return df\n",
    "    return (\n",
    "        df.groupby(['begin', 'end', 'variant_id'], dropna=False, as_index=False)\n",
    "        .agg({col: (lambda x: ','.join(x.astype(str).unique())) if col == 'alternativeSequence' else 'first'\n",
    "              for col in df.columns})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2673ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, features_df = get_protein_variation(accession)\n",
    "features_df['variant_id'] = features_df.apply(get_variant_id, axis=1)\n",
    "features_df['variation_position'] = features_df.apply(get_position, axis=1)\n",
    "features_df['ref_aa'] = features_df.apply(lambda x: get_ref_aa_sequence(data.get('sequence'), x), axis=1)\n",
    "features_df = combine_alternative_sequences(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56203851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching frequency data for variant rs1559599007: 500 Server Error: Internal Server Error for url: https://www.ncbi.nlm.nih.gov/snp/rs1559599007/download/frequency\n"
     ]
    }
   ],
   "source": [
    "results = list(zip(*[parse_frequency_reponse(get_frequency(variant)) for variant in features_df['variant_id']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ee8ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.DataFrame(results[0])\n",
    "frequencies_df = pd.concat(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e21be667",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([features_df, metadata_df], axis=1)\n",
    "final_merged = pd.merge(merged, frequencies_df, on=variant_index, how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55340733",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged[['Ref Allele NA', 'Ref Allele Prob']] = final_merged['Ref Allele'].str.split('=', n=1, expand=True)\n",
    "final_merged[['Alt Allele NA', 'Alt Allele Prob']] = final_merged['Alt Allele'].str.split('=', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80076ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_filtered = final_merged.loc[:, final_merged.isna().mean() < 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "171ac6f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Remove columns where all values are the same and put these into a summary dictionary\u001b[39;00m\n\u001b[32m      2\u001b[39m summary = {}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m nunique = \u001b[43mfinal_merged_filtered\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnunique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m final_merged_filtered.columns[nunique == \u001b[32m1\u001b[39m]:\n\u001b[32m      5\u001b[39m     summary[col] = final_merged_filtered[col].iloc[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/frame.py:11843\u001b[39m, in \u001b[36mDataFrame.nunique\u001b[39m\u001b[34m(self, axis, dropna)\u001b[39m\n\u001b[32m  11805\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnunique\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: Axis = \u001b[32m0\u001b[39m, dropna: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Series:\n\u001b[32m  11806\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  11807\u001b[39m \u001b[33;03m    Count number of distinct elements in specified axis.\u001b[39;00m\n\u001b[32m  11808\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m  11841\u001b[39m \u001b[33;03m    dtype: int64\u001b[39;00m\n\u001b[32m  11842\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m11843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnunique\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/frame.py:10381\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10367\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10369\u001b[39m op = frame_apply(\n\u001b[32m  10370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10371\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10379\u001b[39m     kwargs=kwargs,\n\u001b[32m  10380\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/base.py:1067\u001b[39m, in \u001b[36mIndexOpsMixin.nunique\u001b[39m\u001b[34m(self, dropna)\u001b[39m\n\u001b[32m   1032\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnunique\u001b[39m(\u001b[38;5;28mself\u001b[39m, dropna: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   1034\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[33;03m    Return number of unique elements in the object.\u001b[39;00m\n\u001b[32m   1036\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1065\u001b[39m \u001b[33;03m    4\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1067\u001b[39m     uniqs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dropna:\n\u001b[32m   1069\u001b[39m         uniqs = remove_na_arraylike(uniqs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/series.py:2416\u001b[39m, in \u001b[36mSeries.unique\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[32m   2354\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2355\u001b[39m \u001b[33;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[32m   2356\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2414\u001b[39m \u001b[33;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[32m   2415\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/base.py:1029\u001b[39m, in \u001b[36mIndexOpsMixin.unique\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1027\u001b[39m     result = values.unique()\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m     result = \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/algorithms.py:401\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munique\u001b[39m(values):\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[32m    310\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    399\u001b[39m \u001b[33;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/lib/python3.13/site-packages/pandas/core/algorithms.py:440\u001b[39m, in \u001b[36munique_with_mask\u001b[39m\u001b[34m(values, mask)\u001b[39m\n\u001b[32m    438\u001b[39m table = hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     uniques = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     uniques = _reconstruct_data(uniques, original.dtype, original)\n\u001b[32m    442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7260\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7203\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Remove columns where all values are the same and put these into a summary dictionary\n",
    "summary = {}\n",
    "nunique = final_merged_filtered.nunique(dropna=False)\n",
    "for col in final_merged_filtered.columns[nunique == 1]:\n",
    "    summary[col] = final_merged_filtered[col].iloc[0]\n",
    "final_merged_filtered = final_merged_filtered.loc[:, nunique > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e2f0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.to_csv(f\"{accession}_protein_variation.csv\", index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
